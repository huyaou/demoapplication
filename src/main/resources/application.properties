server.port=8080

user.uid=88
user.name=huyaou
user.age=25
user.address=beijing
user.phoneNum=12345678
#netty
netty.port=9896
netty.host=127.0.0.1

#mysql
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.username=root
spring.datasource.password=root
spring.datasource.url=jdbc:mysql://localhost:3306/demo?useUnicode=true&characterEncoding=utf-8&useSSL=false&serverTimezone=Asia/Shanghai

spring.jpa.show-sql=true
spring.jpa.database=mysql

spring.jpa.hibernate.ddl-auto=none
spring.jpa.properties.hibernate.enable_lazy_load_no_trans=true
spring.jpa.properties.hibernate.hbm2ddl.auto=none
spring.jpa.properties.hibernate.temp.use_jdbc_metadata_defaults=false

spring.datasource.continue-on-error=true

spring.datasource.hikari.maximum-pool-size=100
spring.datasource.hikari.connection-timeout=90000
spring.datasource.hikari.validation-timeout=5000
spring.datasource.hikari.idle-timeout=60000
spring.datasource.hikari.login-timeout=5
spring.datasource.hikari.max-lifetime=60000

#Kafka生产者配置信息
#spring.kafka.bootstrap-servers=127.0.0.1:9092

#spring.kafka.producer.batch-size=16384
#spring.kafka.producer.retries=0
#spring.kafka.producer.buffer-memory=33554432
#spring.kafka.producer.acks=1

#=============== consumer  =======================
# 指定默认消费者group id --> 由于在kafka中，同一组中的consumer不会读取到同一个消息，依靠groud.id设置组名
#spring.kafka.consumer.group-id=testGroup
# smallest和largest才有效，如果smallest重新0开始读取，如果是largest从logfile的offset读取。一般情况下我们都是设置smallest
#spring.kafka.consumer.auto-offset-reset=earliest
# enable.auto.commit:true --> 设置自动提交offset
#spring.kafka.consumer.enable-auto-commit=true
#如果'enable.auto.commit'为true，则消费者偏移自动提交给Kafka的频率（以毫秒为单位），默认值为5000。
#spring.kafka.consumer.auto-commit-interval=100

# 指定消息key和消息体的编解码方式
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer